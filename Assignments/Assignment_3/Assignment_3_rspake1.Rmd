---
title: "Assignment_3_rspake1"
output: html_document
---
## Set up for our model for pretrained word embedding first

```{r cars}
library(keras)
maxlen <- 150
training_samples <- 100
validation_samples <- 10000
max_features <- 10000

imdb <- dataset_imdb(num_words = max_features)
c(c(x_train, y_train), c(x_test, y_test)) %<-% imdb

Data = imdb$train$x
Labels = imdb$train$y

```


## Time to set the right parameters 

We will be using those parameters we established earlier for validation and training size. 

```{r}
x_train <- Data[1:training_samples]
x_val <- Data[(training_samples + 1):
                              (training_samples + validation_samples)]
y_train <- Labels[1:training_samples]
y_val <- Labels[(training_samples + 1):
                              (training_samples + validation_samples)]

```

## Preprocessing for embedding

```{r}
glove_dir <- "C:/Users/rspake1/Downloads/glove.6B"
lines <- readLines(file.path(glove_dir, "glove.6B.100d.txt"))

embeddings_index <- new.env(hash = TRUE, parent = emptyenv())
for (i in 1:length(lines)) {
  line <- lines[[i]]
  values <- strsplit(line, " ")[[1]]
  word <- values[[1]]
  embeddings_index[[word]] <- as.double(values[-1])
}

cat("Found", length(embeddings_index), "word vectors. \n")
```
## building our embedding matrix

```{r}
embedding_dim <- 100

embedding_matrix <- array(0, c(max_features, embedding_dim))

for(word in names(word_index)) {
  index <- word_index[[word]]
  if (index < max_features) {
    embedding_vector <- embeddings_index[[word]]
    if (!is.null(embedding_vector))
      embedding_matrix[index+1,] <- embedding_vector
  }
}

```


```{r}
model1 <- keras_model_sequential() %>% 
  layer_embedding(input_dim = 10000, output_dim = 8,
                  input_length = maxlen) %>%
  layer_flatten() %>%
  layer_dense(units = 1, activation = "sigmoid")

model1 %>% compile(
  optimizer = "rmsprop",
  loss = "binary_crossentropy",
  metrics = c("acc")
)
history <- model1 %>% fit(
  x_train, y_train,
  epochs = 10,
  batch_size = 32,
  validation_data = list(x_test,y_test)
)
```


## Including Plots

You can also embed plots, for example:

```{r model}
library(keras)

max_features <- 10000
maxlen <- 150
batch_size <- 32
cat("Loading data...\n")
imdb <- dataset_imdb(num_words = max_features)
c(c(input_train, y_train), c(input_test,y_test)) %<-% imdb 
cat(length(input_train), "train sequences\n")
cat(length(input_test), "test seuences")

cat("Pad sequences (samples x times)\n")
input_train <- pad_sequences(input_train, maxlen = maxlen)
input_test <- pad_sequences(input_test, maxlen = maxlen)
cat("input_train shape:", dim(input_train), "\n")
cat("input_test shape:", dim(input_test), "\n")
```

```{r}

```

Note that the `echo = FALSE` parameter was added to the code chunk to prevent printing of the R code that generated the plot.
